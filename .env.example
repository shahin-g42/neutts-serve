# NeuTTS-Air TTS Service Configuration
# Copy this file to .env and adjust the values as needed

# =============================================================================
# Model Configuration
# =============================================================================

# NeuTTS-Air backbone model repository
MODEL_CHECKPOINT_PATH=neuphonic/neutts-air

# NeuCodec repository for audio encoding/decoding
CODEC_REPO=neuphonic/neucodec

# =============================================================================
# Device Configuration
# =============================================================================

# Device for backbone model (cpu/cuda)
BACKBONE_DEVICE=cuda

# Device for codec model (cpu/cuda)
CODEC_DEVICE=cuda

# =============================================================================
# Backend Configuration
# =============================================================================

# Enable vLLM for accelerated inference (requires CUDA)
USE_VLLM=true

# Enable GGUF quantized model (requires llama-cpp-python)
# Set to true if using neuphonic/neutts-air-q4-gguf
USE_GGUF=false

# Use AsyncLLMEngine for streaming (vLLM only)
USE_ASYNC_ENGINE=true

# =============================================================================
# Server Configuration
# =============================================================================

# Server host and port
HOST=127.0.0.1
PORT=8002

# Enable debug mode
DEBUG=false

# =============================================================================
# Model Parameters
# =============================================================================

# Maximum context length
MAX_CONTEXT=2048

# GPU memory utilization for vLLM (0.0-1.0)
GPU_MEMORY_UTILIZATION=0.7

# Random seed for generation
SEED=42

# =============================================================================
# Synthesis Parameters
# =============================================================================

# Sampling temperature (higher = more random)
TEMPERATURE=1.0

# Maximum tokens to generate
MAX_TOKENS=2048

# Minimum tokens to generate
MIN_TOKENS=50

# Top-p (nucleus) sampling
TOP_P=1.0

# Top-k sampling
TOP_K=50

# =============================================================================
# Streaming Parameters
# =============================================================================

# Number of tokens per audio chunk for streaming
STREAMING_FRAMES_PER_CHUNK=25

# Overlap frames between chunks
STREAMING_OVERLAP_FRAMES=1

# Future context tokens for streaming
STREAMING_LOOKFORWARD=5

# Past context tokens for streaming
STREAMING_LOOKBACK=50

# =============================================================================
# Audio Parameters
# =============================================================================

# Output audio sample rate (Hz)
SAMPLE_RATE=24000

# Codec hop length in samples
HOP_LENGTH=480

# =============================================================================
# Phonemizer Configuration
# =============================================================================

# Language for phonemizer
# Supported languages: en-us, en-gb, es, fr, de, it, pt, ru, zh, ja, ko, etc.
# See: https://github.com/bootphon/phonemizer#supported-languages
PHONEMIZER_LANGUAGE=en-us

# Enable phonemization (set to false to pass text directly without phoneme conversion)
# When disabled, the model will receive raw text instead of phonemes
# Useful for languages not supported by espeak or for custom text preprocessing
ENABLE_PHONEMIZATION=true

# Preserve punctuation in phonemization
PHONEMIZER_PRESERVE_PUNCTUATION=true

# Include stress markers in phonemization
PHONEMIZER_WITH_STRESS=true

# Path to espeak-ng binary (optional, for custom installations)
# PHONEMIZER_ESPEAK_PATH=/usr/local/bin/espeak-ng

# Path to espeak-ng library (optional, for custom installations)
# PHONEMIZER_ESPEAK_LIBRARY=/usr/local/lib/libespeak-ng.so

# =============================================================================
# Logging Configuration
# =============================================================================

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Path to log file
LOG_FILE=logs/tts_service.log
